{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=rtl>\n",
        "\n",
        "\n",
        "در این تمرین، یک مدل درخت تصمیم به‌صورت دستی برای داده‌های معروف Iris پیاده‌سازی شد. ابتدا داده‌ها نرمال‌سازی شدند و سپس با استفاده از تابعی بازگشتی، درخت تصمیم با معیار Gini ساخته شد. برای هر گره، بهترین ویژگی و مقدار آستانه به‌صورت بهینه انتخاب شد تا داده‌ها به صورت حداکثری از هم جدا شوند.\n",
        "\n",
        "بعد از ساخت مدل، آن را روی مجموعه تست ارزیابی کردیم و معیارهای مختلفی از جمله دقت، precision، recall و f1-score محاسبه شدند. تمام این مقادیر بالا بودند که نشان می‌دهد درخت تصمیم توانسته به‌خوبی ساختار داده را یاد بگیرد و تعمیم بدهد.\n",
        "\n",
        "ساختار نهایی درخت نیز ساده ولی مؤثر بود؛ به‌گونه‌ای که کلاس Setosa تنها با یک شرط از بقیه جدا شد و برای تفکیک Versicolor و Virginica از دو ویژگی دیگر با چند تقسیم اضافی استفاده شد. این نتایج نشان می‌دهد که درخت تصمیم با عمق محدود هم توانسته ساختار داده‌ها را به‌خوبی یاد بگیرد و دسته‌بندی دقیقی انجام دهد.\n",
        "\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "9dfQC4DswnFJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9e92f1a3-3e81-4ec6-a567-890827b0555c",
        "_uuid": "e5338e8c3fa6dc8f410d8b868aa78cb54621780b",
        "collapsed": true,
        "id": "0c8jQ7HSuiSO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris\n",
        "# from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn_k4zMcuiSW",
        "outputId": "ccb84214-e272-4b78-cdf4-7a0cd896d662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy      : 0.9666666666666667\n",
            "precision (µ) : 0.9696969696969697\n",
            "recall   (µ)  : 0.9666666666666667\n",
            "f1-score (µ)  : 0.9665831244778612\n",
            "\n",
            "[X[2] < -0.431]\n",
            "-->True:\n",
            "    Predict -> 0\n",
            "-->False:\n",
            "    [X[3] < 0.659]\n",
            "    -->True:\n",
            "        [X[2] < 0.706]\n",
            "        -->True:\n",
            "            Predict -> 1\n",
            "        -->False:\n",
            "            Predict -> 2\n",
            "    -->False:\n",
            "        [X[2] < 0.649]\n",
            "        -->True:\n",
            "            Predict -> 2\n",
            "        -->False:\n",
            "            Predict -> 2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "scaler = StandardScaler().fit(X)\n",
        "X_scaled = scaler.transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value\n",
        "\n",
        "def gini(y):\n",
        "    m = len(y)\n",
        "    if m == 0:\n",
        "        return 0\n",
        "    _, counts = np.unique(y, return_counts=True)\n",
        "    probs = counts / m\n",
        "    return 1 - np.sum(probs ** 2)\n",
        "\n",
        "def best_split(X, y):\n",
        "    best_feat, best_thresh, best_imp = None, None, float('inf')\n",
        "    n_features = X.shape[1]\n",
        "    for f in range(n_features):\n",
        "        for t in np.unique(X[:, f]):\n",
        "            left = y[X[:, f] < t]\n",
        "            right = y[X[:, f] >= t]\n",
        "            if len(left) == 0 or len(right) == 0:\n",
        "                continue\n",
        "            imp = (len(left) * gini(left) + len(right) * gini(right)) / len(y)\n",
        "            if imp < best_imp:\n",
        "                best_imp, best_feat, best_thresh = imp, f, t\n",
        "    return best_feat, best_thresh\n",
        "\n",
        "def build_tree(X, y, max_depth=5, min_size=5, depth=0):\n",
        "    if len(set(y)) == 1 or len(y) < min_size or depth >= max_depth:\n",
        "        labels, counts = np.unique(y, return_counts=True)\n",
        "        return Node(value=labels[np.argmax(counts)])\n",
        "    feat, thresh = best_split(X, y)\n",
        "    if feat is None:\n",
        "        labels, counts = np.unique(y, return_counts=True)\n",
        "        return Node(value=labels[np.argmax(counts)])\n",
        "    mask = X[:, feat] < thresh\n",
        "    left = build_tree(X[mask], y[mask], max_depth, min_size, depth+1)\n",
        "    right = build_tree(X[~mask], y[~mask], max_depth, min_size, depth+1)\n",
        "    return Node(feature=feat, threshold=thresh, left=left, right=right)\n",
        "\n",
        "def predict_one(x, node):\n",
        "    if node.value is not None:\n",
        "        return node.value\n",
        "    if x[node.feature] < node.threshold:\n",
        "        return predict_one(x, node.left)\n",
        "    else:\n",
        "        return predict_one(x, node.right)\n",
        "\n",
        "def predict(X, tree):\n",
        "    return np.array([predict_one(x, tree) for x in X])\n",
        "\n",
        "def print_tree(node, indent=\"\"):\n",
        "    if node.value is not None:\n",
        "        print(indent + \"Predict ->\", node.value)\n",
        "        return\n",
        "    print(indent + f\"[X[{node.feature}] < {node.threshold:.3f}]\")\n",
        "    print(indent + \"-->True:\")\n",
        "    print_tree(node.left, indent + \"    \")\n",
        "    print(indent + \"-->False:\")\n",
        "    print_tree(node.right, indent + \"    \")\n",
        "\n",
        "tree = build_tree(X_train, y_train)\n",
        "y_pred = predict(X_test, tree)\n",
        "\n",
        "print(\"accuracy      :\", accuracy_score(y_test, y_pred))\n",
        "print(\"precision (µ) :\", precision_score(y_test, y_pred, average='macro'))\n",
        "print(\"recall   (µ)  :\", recall_score(y_test, y_pred, average='macro'))\n",
        "print(\"f1-score (µ)  :\", f1_score(y_test, y_pred, average='macro'))\n",
        "print()\n",
        "print_tree(tree)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}